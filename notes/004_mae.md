# Masked Autoencoders Are Scalable Vision Learners

[Paper](https://arxiv.org/pdf/2111.06377.pdf) | [Talk](https://www.bilibili.com/video/BV1sq4y1q77t?spm_id_from=333.999.0.0)

## MAE与Transformer、BERT、ViT的关系

<img src="https://user-images.githubusercontent.com/22740819/146364785-7fc96742-9bc4-49ab-9f88-0d7044239cb4.png" width=300>

- Transformer: 一个纯基于attention的编码器和解码器，用于机器翻译任务
- NERT: 使用一个Transformer的编码器，拓展到更一般的NLP任务，使用了完型填空的自监督的预训练机制
- ViT: Transformer在CV领域的应用，预训练阶段是有监督的方式
- MAE: 可看作CV领域的BERT，将预训练过程扩展到无监督方式，同样通过完形填空的方式，与BERT相同

## Part1. 标题&作者

带掩码的自编码器是一个可扩展的视觉学习器

- scalable: 可扩展的，如果你的算法比较快就用efficient，如果比较大就用scalable
- autoencoder: auto并不是自动的意思，而是 自 的意思；这种说法的特点是因为你的样本和标签是同一个东西

## Part2. 摘要

- MAE是一个针对计算机视觉问题的可扩展的自监督学习方法
- 随机遮挡部分图像patch，然后恢复这些被遮挡的块
- 非对称的encoder-decoder架构
- encoder只作用在可见的patch上，被mask掉的patch不做计算，可节约计算
- decoder用于重构被mask掉的像素
- mask掉大量的patch（如75%）才有可能使自监督任务work，否则通过简单的插值就可以了，无法学习到有效的信息
- MAE只是用小规模数据集，并且使用自监督方法就可以达到很好的效果

## Part3. 关键图

<img src="https://user-images.githubusercontent.com/22740819/146370679-4a661314-422c-4bc6-bc7b-3200466f4c59.png" width=400>

- 对输入图像切分patch，然后对部分patch进行mask操作，把未被mask掉的部分取出来组成输入序列
- 把序列送入encoder中（ViT），得到每一个patch的向量表示
- 把encoder输出的序列拉长，因为需要把mask掉的patch放回原位置；没被mask掉的patch就是填上ViT后输出的特征，被mask掉的patch就只有位置信息
- 然后将新的序列送入到decoder中，然后decoder把里面的像素信息全部重构回来；target就是原始未被mask的图片
- 图中encoder比decoder画的面积大，表示主要计算量在encoder部分
- 接下游任务时只需要用到encoder，并且图片也不需要做mask，直接切patch，送入encoder得到每个patch的向量表示

## Part4. 结论

## Part5. 相关工作

## Part6. MAE模型

## Part7. 实验

## Part8. 评论
