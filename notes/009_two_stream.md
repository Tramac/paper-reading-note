# Two-Stream Convolutional Networks for Action Recognition in Videos

[Paper](https://arxiv.org/pdf/1406.2199.pdf) | [Talk](https://www.bilibili.com/video/BV1mq4y1x7RU?spm_id_from=333.999.0.0)

视频本身是一个很好的数据来源，比2D的单个图像能够包含更多的信息，比如物体之间移动的信息、长期的时序信息、音频信号，非常适合做多模态学习。

双流网络是视频理解的一篇开山之作，它是第一个在视频领域能够让卷积神经网络可以和最好的手工特征打成平手。

## Part1.标题&作者

双流卷积神经网络用来做视频中的动作识别。

Two-Stream: 顾名思义，就是使用了两个卷积神经网络。

<img src="https://user-images.githubusercontent.com/22740819/155945646-ac96ce19-f01f-43d4-b565-9498dfa0e6cb.png" width=600> 

对于视频理解任务，一些早期的工作是把视频抽一些关键帧，分别经过一个CNN，最后将结果合并。或者将这些帧叠起来一起送给CNN，然后在网络中做一些early fusion，late fusion等，达到一种时空学习的效果。但是这些工作的效果都差强人意，甚至比不上手工设计的特征。

作者认为，之所以用一个CNN无法处理好视频问题，是因为CNN它比较擅于学习局部特征，不擅长去学习视频之中物体的移动规律。既然如此，那就事先把移动信息Motion-information提取好，也就是光流optical flow，然后让CNN直接从光流到动作学得一个映射。所以，加入一支关注Motion-information的分支(Temporal stream ConvNet)，这也就是two-stream的来源。

空间流的输入就是一张单帧图片，输出是一个分类的概率，时间流输入是一系列的光流图片，输出也是一个分类的概率，最后将两个分类概率加权平均，得到最终的预测，这就是双流网络。

**Optical Flow:** 光流是描述视频中各种物体是如何运动的。它是一个可以有效描述物体运动的特征，可以过滤背景、人物性别、穿着等等不必要的噪声，最后提取的特征完全专注于动作本身。

作者团队来自牛津大学的VGG组。

## Part2.摘要

这篇论文研究了如何使用深度卷积神经网络去做视频里的动作识别，主要的难点就是如何同时学习两种信息，一种是从静止的图像上获得appearance信息，包括形状、大小、颜色等；另一种就是物体之间的移动信息，也可以看作是视频中的时序信息。

该论文的贡献有三点：

- 提出一个双流网络：由空间流与时间流两个神经网络组成；
- 证实了即使是在少量的训练数据下，一个直接在光流数据上训练的神经网络也能取得很好的效果；
- 为了弥补训练数据上的不足，使用multi-task的学习方法，在两个数据集上去同时训练一个网络；

## Part3.引言

- 与2D图像分类任务相比，视频中的时序信息可以为识别工作提供另外一个重要线索；
- 使用视频数据的好处：视频可以提供很好的一种数据增强，因为在一个视频中，同一个物体会经历各种各样的形变、遮挡、光照改变等，这种改变多样又自然，比那些生硬的数据增强要更好；

## Part4.相关工作

- 很大程度上，视频领域的进展都是被图像领域的进展推动着走的，一般都是先有图像上的突破，然后再将方法移植到视频任务上；
- 最好的手工特征方法是用了视频前后帧点和点之间的轨道信息（dense point trajectories）；
- 之前基于神经网络的工作往往是把一系列视频帧送给网络，让模型自己去学习时空信息，使最后学得跟运动信息相关的特征，但是该方式比较难；
- DeepVideo提供的Sports-1M数据集包含100w个视频（视频帧数量超过10亿），而Kinetic和someting-someting数据集也都只有20w个视频；
- DeepVideo作者发现，如果将视频帧一张张的送给2D网络和把一系列视频帧送给3D网络或具有时空学习能力的2D网络效果是一样的，说明这种方式的时空学习并没有真的抓住物体之间的运动信息；

## Part5.双流模型

视频可以很自然的被拆分为空间部分与时间部分。空间部分就是所说的appearance信息，主要用来描述视频中的场景和物体的；时间部分主要用来描述视频中的物体是如何运动的。根据该现象，本文提出了一个双流网络框架，空间流去学习空间特征，时间流去学习运动特征，最后结果通过late fusion合并得到最终的预测。

<img src="https://user-images.githubusercontent.com/22740819/156122311-5c45c793-f302-4a14-8cbd-edcc3f9fc37e.png" width=600> 

***Spatial stream ConvNet***

- 空间流网络的输入是一张一张的视频帧，用静止图像做动作识别，其实就是图像分类任务；
- 图像中的appearace信息本身就是一个很有用的信息，因为很多动作往往都是和对应的物体联系在一起的，比如弹钢琴、打篮球等；
- 空间流网络用单帧图像作为输入的方式，就可以拿ImageNet来做预训练；
- 空间流网络基本是一个AlexNet，5层卷积+2层全连接层；

***Temporal stream ConvNet***

